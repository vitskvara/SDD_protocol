{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vít Škvára - Samoorganizace a dolování dat/Self-organization and data mining\n",
    "\n",
    "# Kernel methods for multiple-instance learning problem\n",
    "\n",
    "In this protocol, we explore the possibily of using kernel methods, namely smallest enclosing hypersphere, for the task of anomaly detection under the multiple-instance learning paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-instance learning (MIL)\n",
    "\n",
    "In multiple-instance learning (MIL), the problem of supervised binary classification is made more difficult for the learner due to a number of reasons. Firstly, instead of having a set of instances (feature vectors) labeled as negative or positive, a number of _bags_ of instances is received, where the whole bags are labeled as positive or negative. Every bag consists of a (possibly different) number of instances whose individual labels are not known. The common conception is that a bag is labeled negative if all instances in it are negative, but if even a single instance is positive, then the label of the bag is also positive. Secondly, the ratio of negative to positive instances in a bag can be arbitrarily high. In real-world problems however, this presumption can be violated and positive and negative bags may be generated from entirely different sources. \n",
    "\n",
    "Our motivation comes from the area of malware detection in computers connected to a network whose activity is supervised. In such a case, the communication of every computer with the outside world (using a HTTP protocol) goes through a common hub. The observer, for a limited time frame, collects all HTTP requests of the computers in the network. From each request, we substract a number of features (e.g. bytes sent and received, request lenght in ms). A collection of such instances for one computer creates a bag. Additionaly, some computers are known to be infected with malware that communicates with the Internet. Their bags are then labeled as positive and together with bags of some uninfected computers compose a training dataset. Presumably, positive bags should contain a number of positive instances - requests created by the malware. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel theory basics\n",
    "\n",
    "Firstly, we will give a brief introduction to kernel methods and the smallest hypersphere algorithm that will be used to detect outliers or anomalies. A kernel is a mapping\n",
    "\\begin{equation}\n",
    "    \\kappa(x,y) = \\langle \\phi(x), \\phi(y) \\rangle\n",
    "\\end{equation}\n",
    "that encodes data $x,y \\in \\mathcal{X}$ to feature space $\\mathcal{F}$ using a scalar product of an embedding map \n",
    "\\begin{equation}\n",
    "    \\phi:\\mathcal{X} \\rightarrow \\mathcal{F}.\n",
    "\\end{equation}\n",
    "\n",
    "The trick of kernel methods is that for a training dataset $X= \\lbrace x_1, x_2, \\dots, x_m \\rbrace$, they are able to use standar linear machine learning techniques on the richer feature space $\\mathcal{F}$ without directly computing the potentially computationally demanding mapping $\\phi(x_i), i = 1, 2, \\dots, m$. Instead, it is sufficient to obtain the kernel matrix $G$, which satistfies \n",
    "\\begin{equation}\n",
    "    G_{ij} = \\kappa(x_i,x_j) = \\langle \\phi(x_i), \\phi(x_j) \\rangle.\n",
    "\\end{equation}\n",
    "This matrix is symmetric and enables us to use a large number of classical algorithms in the feature space.\n",
    "\n",
    "The quadratic kernel is one of the simplest. It is defined as \n",
    "\\begin{equation}\n",
    "    \\kappa(x,y) = \\langle x, y \\rangle^2\n",
    "\\end{equation}\n",
    "and its corresponding feature map for $\\mathcal{X} = \\mathbb{R}^2$ is \n",
    "\\begin{equation}\n",
    "    \\phi(x) = (x_1^2, x_2^2, \\sqrt{2}x_1x_2) \n",
    "\\end{equation}\n",
    "embeds the original samples to feature space $\\mathcal{F} = \\mathbb{R}^3$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The smallest enclosing hypersphere algorithm\n",
    "\n",
    "The idea is to find a smallest enclosing hypersphere of the training dataset $X$ in feature space $\\mathcal{F}$ that is defined by center $c \\in \\mathcal{F}$ and radius $r\\in \\mathbb{R}$. This translates to a nonlinear optimization problem for an unknown weight vector $\\alpha \\in \\mathbb{R}^n$ defined as\n",
    "\\begin{equation}\n",
    "    \\max_{\\alpha} W(\\alpha) = \\alpha^T \\text{diag}(G) - \\alpha^T G \\alpha\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\text{s.t.} \\sum_{i=1}^n \\alpha_i = 1, \\alpha_i \\geq 0, i = 1, \\dots, n\n",
    "\\end{equation}\n",
    "where $\\text{diag}(G)$ is a vector containing the diagonal elements of $G$.\n",
    "\n",
    "Let $\\alpha^*$ denote the found optimal solution. Then the following holds\n",
    "\\begin{equation}\n",
    "    r^* = \\sqrt{W(\\alpha^*)}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    c^* = \\sum_{i=1}^n \\alpha_i^* \\phi(x_i)\n",
    "\\end{equation}\n",
    "where $r^*, c^*$ are the radius and center of the smallest sphere that contains all the training data.\n",
    "\n",
    "For a new sample $x$, the testing function that determines whether the point lies inside or outside the sphere has the following  form\n",
    "\\begin{equation}\n",
    "    f(x) = \\kappa(x,x) - 2 \\sum_{i=1}^n \\alpha_i^* \\kappa(x_i,x) + \\alpha^{*T} G \\alpha^* - r^{*2}.\n",
    "\\end{equation}\n",
    "If $f(x) \\geq 0$, then the sample lies inside the sphere, otherwise it is outside.\n",
    "\n",
    "Note that for the computation of the testing function, the exact form  of the feature map $\\phi(x)$ is not needed as it is not required here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JLD\n",
    "using Convex, SCS # for optimization\n",
    "using ClobberingReload # for deprecation warnings supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_statistics"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this contains some helper functions for MIL manipulation\n",
    "include(\"/home/vit/Dropbox/vyzkum/cisco/kod/lib/julia/VBMatrixFactorization/examples/mil_util.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract type kernel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct quadkernel <: kernel\n",
    "    c # offset\n",
    "    km # kernel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct polykernel <: kernel\n",
    "    p # polynomial order\n",
    "    c # offset\n",
    "    x # the data\n",
    "    km # kernel matrix\n",
    "    ϕ # generating function\n",
    "end\n",
    "\n",
    "# abbreviated constructor\n",
    "polykernel(X::AbstractArray, p::Int, c = 0.0) = \n",
    "     polykernel(p, ones(size(X,1))*c, X, (X*X').^p, nothing)\n",
    "\n",
    "# overloaded for direct calling\n",
    "(pk::polykernel)(x) = (x'*x + c)^(pk.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polykernel(2, [0.0238552 0.29988 … 0.855878 0.301596; 0.851979 0.939919 … 0.929722 0.242266; 0.552347 0.137169 … 0.976116 0.76581], [2.1257 1.50628 2.70062; 1.50628 6.44282 3.05084; 2.70062 3.05084 5.59467], nothing)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rand(3,6)\n",
    "krnl = polykernel(X,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel_sh"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernelized smallest hypersphere for anomaly detection\n",
    "mutable struct kernel_sh\n",
    "    k::kernel\n",
    "    α\n",
    "    r\n",
    "    D\n",
    "    c\n",
    "    opt\n",
    "end\n",
    "\n",
    "# constructor\n",
    "kernel_sh(k::kernel) = kernel_sh(k, Array{Float64,1}([]), NaN, NaN, NaN, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel_sh(polykernel(2, [0.0238552 0.29988 … 0.855878 0.301596; 0.851979 0.939919 … 0.929722 0.242266; 0.552347 0.137169 … 0.976116 0.76581], [2.1257 1.50628 2.70062; 1.50628 6.44282 3.05084; 2.70062 3.05084 5.59467], nothing), Float64[], NaN, NaN, NaN, false)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksh = kernel_sh(krnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91msyntax: incomplete: \"function\" at In[11]:37 requires end\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91msyntax: incomplete: \"function\" at In[11]:37 requires end\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "W(α,gm) = diag(gm)'*α - sum(gm.*(α*α'))\n",
    "W(ksh::kernel_sh) = W(ksh.α, ksh.k.gm)\n",
    "\n",
    "function find_sphere!(ksh::kernel_sh)\n",
    "    # this is the optimization part using Convex and SCS packages\n",
    "    # setup the variables, objective and constraints\n",
    "    n = size(ksh.k.gm,1)\n",
    "    α = Variable(n, Positive())\n",
    "    dgm = diag(ksh.k.gm)'\n",
    "    dg = ksh.k.gm\n",
    "    objective = dgm*α - quadform(α, dg)\n",
    "    constraints = [sum(α) == 1.0]\n",
    "    problem = maximize(objective, constraints) \n",
    "    # solve\n",
    "    no_warnings() do\n",
    "        solve!(problem)\n",
    "    end\n",
    "    # if succesfully solved, extract and round the optimal solution\n",
    "    if problem.status == :Optimal\n",
    "        ksh.α = round.(problem.solution.primal[1:n], 3)\n",
    "        ksh.opt = true\n",
    "    else\n",
    "        error(\"solution not found!\")\n",
    "    end\n",
    "    \n",
    "    # compute the radius\n",
    "    ksh.r = sqrt(W(ksh))\n",
    "    # compute D for the anomaly score function\n",
    "    ksh.D = ksh.α'*ksh.k.gm*ksh.α - ksh.r^2\n",
    "    # compute the center - but we don't really need this\n",
    "    # also, it may not be possible for some kernels\n",
    "    if !(ksh.k.ϕ == nothing)\n",
    "        ksh.c = ksh.α'*ksh.k.ϕ.(ksh.k.x)\n",
    "    end\n",
    "end\n",
    "\n",
    "function anomaly_score(ksh::kernel_sh, x)\n",
    "    return ksh.k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "\tSCS v1.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2016\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-direct, nnz in A = 24\n",
      "eps = 1.00e-04, alpha = 1.80, max_iters = 20000, normalize = 1, scale = 5.00\n",
      "Variables n = 6, constraints m = 13\n",
      "Cones:\tprimal zero / dual free vars: 2\n",
      "\tlinear vars: 4\n",
      "\tsoc vars: 7, soc blks: 2\n",
      "Setup time: 4.29e-05s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0|      inf       inf      -nan      -inf       inf       inf  2.28e-05 \n",
      "   100| 1.34e-03  2.28e-02  1.92e-02 -8.82e-01 -9.36e-01  7.39e-17  6.60e-05 \n",
      "   200| 4.64e-05  6.51e-04  5.01e-04 -8.93e-01 -8.95e-01  7.35e-17  1.07e-04 \n",
      "   240| 1.49e-05  3.91e-05  4.08e-06 -8.93e-01 -8.93e-01  7.35e-17  1.24e-04 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Solved\n",
      "Timing: Solve time: 1.26e-04s\n",
      "\tLin-sys: nnz in L factor: 49, avg solve time: 1.64e-07s\n",
      "\tCones: avg projection time: 5.54e-08s\n",
      "----------------------------------------------------------------------------\n",
      "Error metrics:\n",
      "dist(s, K) = 4.6461e-17, dist(y, K*) = 0.0000e+00, s'y/|s||y| = 5.6799e-17\n",
      "|Ax + s - b|_2 / (1 + |b|_2) = 1.4902e-05\n",
      "|A'y + c|_2 / (1 + |c|_2) = 3.9115e-05\n",
      "|c'x + b'y| / (1 + |c'x| + |b'y|) = 4.0787e-06\n",
      "----------------------------------------------------------------------------\n",
      "c'x = -0.8932, -b'y = -0.8932\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "find_sphere!(ksh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5168458726337386"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksh.D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
